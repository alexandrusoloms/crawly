# crawly
A fast, reliable and simple Python scraping module



## How it works

`crawly` makes use of concurrent threads to make requests. It uses proxies and changes user-agents making it adequate for 'hyper-scraping' pages within the same domain. As an example I will show you how it works on 5 pages from Wikipedia. Simply click the footnote below.   

[![Alt text](https://img.youtube.com/vi/KVWuAcUAYYo/0.jpg)](https://www.youtube.com/watch?v=KVWuAcUAYYo)



## How to set up

Simply download the repo and add it to $PATH. You can do this in one of two ways:

1. pip install -e
2. adding the path to the repo to .bash_profile or .bashrc









